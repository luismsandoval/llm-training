# LLM From Scratch - Implementation Guide

This guide outlines the key steps for building an LLM with a real-time TypeScript dashboard.

## 1. Transformer Architecture

### Basic Transformer Model
```python
import torch
import torch.nn as nn

class TransformerLM(nn.Module):
    def __init__(self, vocab_size, d_model, n_layers, n_heads, d_ff, max_seq_length, dropout=0.1):
        super().__init__()
        self.token_embedding = nn.Embedding(vocab_size, d_model)
        self.positional_encoding = SinusoidalPositionalEncoding(d_model, max_seq_length)
        
        # Transformer layers
        self.layers = nn.ModuleList([
            TransformerLayer(d_model, n_heads, d_ff, dropout)
            for _ in range(n_layers)
        ])
        
        self.output_projection = nn.Linear(d_model, vocab_size)
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, tokens):
        # Token embeddings + positional encoding
        x = self.token_embedding(tokens)
        x = self.positional_encoding(x)
        x = self.dropout(x)
        
        # Apply transformer layers
        for layer in self.layers:
            x = layer(x)
            
        # Project to vocabulary
        return self.output_projection(x)
```

### Multi-Head Attention
```python
class MultiHeadAttention(nn.Module):
    def __init__(self, d_model, n_heads):
        super().__init__()
        self.d_model = d_model
        self.n_heads = n_heads
        self.d_head = d_model // n_heads
        
        # Linear projections
        self.q_proj = nn.Linear(d_model, d_model)
        self.k_proj = nn.Linear(d_model, d_model)
        self.v_proj = nn.Linear(d_model, d_model)
        self.output_proj = nn.Linear(d_model, d_model)
        
    def forward(self, x, mask=None):
        batch_size = x.shape[0]
        
        # Project and reshape for multi-head attention
        q = self.q_proj(x).view(batch_size, -1, self.n_heads, self.d_head).transpose(1, 2)
        k = self.k_proj(x).view(batch_size, -1, self.n_heads, self.d_head).transpose(1, 2)
        v = self.v_proj(x).view(batch_size, -1, self.n_heads, self.d_head).transpose(1, 2)
        
        # Scaled dot-product attention
        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.d_head ** 0.5)
        if mask is not None:
            scores = scores.masked_fill(mask == 0, -1e9)
        attn_weights = torch.softmax(scores, dim=-1)
        attn_output = torch.matmul(attn_weights, v)
        
        # Reshape and project output
        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)
        return self.output_proj(attn_output)
```

## 2. GPU-Optimized Training

### Mixed Precision and Gradient Accumulation
```python
import torch.cuda.amp as amp

class Trainer:
    def __init__(self, model, dataset, batch_size, gradient_accumulation_steps=1, fp16=True):
        self.model = model
        self.dataset = dataset
        self.batch_size = batch_size
        self.gradient_accumulation_steps = gradient_accumulation_steps
        self.fp16 = fp16
        self.scaler = amp.GradScaler() if fp16 else None
        self.optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
        
    def train(self, epochs, learning_rate):
        self.model.train()
        
        for epoch in range(epochs):
            running_loss = 0
            self.optimizer.zero_grad()
            
            for i, batch in enumerate(self.dataset):
                # Mixed precision
                with amp.autocast(enabled=self.fp16):
                    outputs = self.model(batch['input_ids'])
                    loss = self.compute_loss(outputs, batch['labels'])
                    # Scale loss by accumulation steps
                    loss = loss / self.gradient_accumulation_steps
                
                # Backward pass with scaling
                if self.fp16:
                    self.scaler.scale(loss).backward()
                else:
                    loss.backward()
                    
                running_loss += loss.item()
                
                # Update weights after accumulation steps
                if (i + 1) % self.gradient_accumulation_steps == 0:
                    if self.fp16:
                        self.scaler.step(self.optimizer)
                        self.scaler.update()
                    else:
                        self.optimizer.step()
                    self.optimizer.zero_grad()
                    
                    # Emit metrics via WebSocket
                    self.emit_metrics({
                        'epoch': epoch,
                        'iteration': i,
                        'loss': running_loss,
                        'lr': learning_rate
                    })
                    running_loss = 0
```

## 3. WebSocket Communication

### Python Backend (FastAPI)
```python
from fastapi import FastAPI, WebSocket
import json

app = FastAPI()

class TrainingMetricsService:
    def __init__(self):
        self.connections = []
        
    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.connections.append(websocket)
        
    def disconnect(self, websocket: WebSocket):
        self.connections.remove(websocket)
        
    async def broadcast(self, metrics):
        for connection in self.connections:
            await connection.send_text(json.dumps(metrics))
            
metrics_service = TrainingMetricsService()

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await metrics_service.connect(websocket)
    try:
        while True:
            # Handle commands from dashboard
            data = await websocket.receive_text()
            command = json.loads(data)
            # Process command (e.g., start/stop training)
    except:
        metrics_service.disconnect(websocket)
```

### TypeScript WebSocket Service
```typescript
// WebSocketService.ts
export class WebSocketService {
  private socket: WebSocket | null = null;
  private url: string;
  private listeners: Map<string, Function[]> = new Map();

  constructor(url: string = 'ws://localhost:8000/ws') {
    this.url = url;
  }

  connect(): void {
    this.socket = new WebSocket(this.url);
    
    this.socket.onmessage = (event) => {
      const data = JSON.parse(event.data);
      this.notifyListeners('metrics', data);
    };
    
    this.socket.onclose = () => {
      this.notifyListeners('disconnect', null);
      // Reconnect logic could go here
    };
  }

  on(event: string, callback: Function): void {
    if (!this.listeners.has(event)) {
      this.listeners.set(event, []);
    }
    this.listeners.get(event)?.push(callback);
  }

  sendCommand(command: string, data: any): void {
    if (this.socket?.readyState === WebSocket.OPEN) {
      this.socket.send(JSON.stringify({
        command,
        data
      }));
    }
  }

  private notifyListeners(event: string, data: any): void {
    const callbacks = this.listeners.get(event) || [];
    callbacks.forEach(callback => callback(data));
  }
}
```

## 4. AWS S3 Integration

### Python S3 Service
```python
import boto3
import os

class S3Service:
    def __init__(self, bucket_name):
        self.s3 = boto3.client('s3')
        self.bucket = bucket_name
        
    def upload_checkpoint(self, checkpoint_path, checkpoint_name):
        """Upload model checkpoint to S3"""
        self.s3.upload_file(
            checkpoint_path,
            self.bucket,
            f"checkpoints/{checkpoint_name}"
        )
        return f"s3://{self.bucket}/checkpoints/{checkpoint_name}"
        
    def download_checkpoint(self, checkpoint_name, local_path):
        """Download model checkpoint from S3"""
        os.makedirs(os.path.dirname(local_path), exist_ok=True)
        self.s3.download_file(
            self.bucket,
            f"checkpoints/{checkpoint_name}",
            local_path
        )
        return local_path
        
    def list_checkpoints(self):
        """List all available checkpoints"""
        response = self.s3.list_objects_v2(
            Bucket=self.bucket,
            Prefix="checkpoints/"
        )
        return [obj['Key'] for obj in response.get('Contents', [])]
```

### TypeScript AWS Service
```typescript
// AWSService.ts
import AWS from 'aws-sdk';

export class AWSService {
  private s3: AWS.S3;
  private bucket: string;
  
  constructor(bucket: string, region: string = 'us-west-2') {
    AWS.config.update({ region });
    this.s3 = new AWS.S3();
    this.bucket = bucket;
  }
  
  async listCheckpoints(): Promise<string[]> {
    const params = {
      Bucket: this.bucket,
      Prefix: 'checkpoints/'
    };
    
    const response = await this.s3.listObjectsV2(params).promise();
    return (response.Contents || []).map(item => item.Key as string);
  }
  
  getCheckpointUrl(checkpointName: string): string {
    return `https://${this.bucket}.s3.amazonaws.com/checkpoints/${checkpointName}`;
  }
}
```

## 5. Performance Benchmarks

### RTX 3090 Expected Performance
- **Model Size**: ~1B parameters with 24GB VRAM
- **Training Speed**: ~10-15k tokens/second
- **Batch Size**: 8-16 with gradient accumulation
- **Memory Optimization**: FP16 mixed precision, gradient checkpointing
- **Training Time**: Varies by dataset size and convergence requirements

## Next Steps

Refer to the detailed checklist in TODO.md for a step-by-step implementation plan.
